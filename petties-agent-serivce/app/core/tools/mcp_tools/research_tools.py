"""
PETTIES AGENT SERVICE - Research Tools (FastMCP)
Code-based tools cho Research Agent - Viáº¿t báº±ng FastMCP

Package: app.core.tools.mcp_tools
Purpose:
    - TÃ¬m kiáº¿m thÃ´ng tin trÃªn web (general-purpose)
    - Web Search (DuckDuckGo/Tavily) - bao gá»“m sáº£n pháº©m, bÃ i viáº¿t, thÃ´ng tin chung
    - Extract content tá»« web pages
    - Video search trÃªn YouTube

Tools:
    - web_search: TÃ¬m kiáº¿m web (DuckDuckGo/Tavily)
    - extract_web_content: Extract thÃ´ng tin tá»« URL (khÃ´ng chá»‰ product)
    - search_youtube_videos: TÃ¬m video hÆ°á»›ng dáº«n

Reference: Technical Scope - Research Agent (Web & Content)
Version: v0.1.0
"""

from app.core.tools.mcp_server import mcp_server
from typing import Dict, Any, List
import httpx
import logging
from duckduckgo_search import DDGS

from app.config.settings import settings

logger = logging.getLogger(__name__)


# ===== RESEARCH TOOLS =====

@mcp_server.tool()
async def web_search(query: str, max_results: int = 5) -> Dict[str, Any]:
    """
    TÃ¬m kiáº¿m thÃ´ng tin trÃªn web (DuckDuckGo/Tavily) - general-purpose

    Args:
        query: Tá»« khÃ³a tÃ¬m kiáº¿m (cÃ³ thá»ƒ lÃ  sáº£n pháº©m, bÃ i viáº¿t, thÃ´ng tin chung)
        max_results: Sá»‘ lÆ°á»£ng káº¿t quáº£ (default: 5)

    Returns:
        Dict chá»©a:
            - query: str
            - results: List[Dict] - Káº¿t quáº£ tÃ¬m kiáº¿m
                - title: str - TiÃªu Ä‘á»
                - url: str - Link
                - snippet: str - Äoáº¡n trÃ­ch
                - source: str - Nguá»“n (tÃªn website)

    Example:
        >>> await web_search("cÃ¡ch chÄƒm sÃ³c chÃ³ con")
        {
            "query": "cÃ¡ch chÄƒm sÃ³c chÃ³ con",
            "results": [
                {
                    "title": "HÆ°á»›ng dáº«n chÄƒm sÃ³c chÃ³ con - PetMart",
                    "url": "https://petmart.vn/...",
                    "snippet": "ChÄƒm sÃ³c chÃ³ con cáº§n chÃº Ã½...",
                    "source": "petmart.vn"
                }
            ]
        }

    Purpose:
        - Research Agent tÃ¬m báº¥t cá»© thá»© gÃ¬ trÃªn web Ä‘Æ°á»£c Main Agent giao phÃ³
        - Bao gá»“m: sáº£n pháº©m, bÃ i viáº¿t y khoa, máº¹o váº·t, thÃ´ng tin chung
        - Æ¯u tiÃªn nguá»“n uy tÃ­n
    """
    try:
        # Use DuckDuckGo Search API
        with DDGS() as ddgs:
            search_results = list(ddgs.text(
                query,
                max_results=max_results
            ))

        results = [
            {
                "title": result.get("title", ""),
                "url": result.get("href", ""),
                "snippet": result.get("body", ""),
                "source": result.get("href", "").split("/")[2] if result.get("href") else ""
            }
            for result in search_results
        ]

        logger.info(f"âœ… Web search: {query} - Found {len(results)} results")
        return {
            "query": query,
            "results": results
        }

    except Exception as e:
        logger.error(f"âŒ Error in web search: {e}")
        return {
            "query": query,
            "results": [],
            "error": str(e)
        }


@mcp_server.tool()
async def extract_web_content(url: str) -> Dict[str, Any]:
    """
    TrÃ­ch xuáº¥t thÃ´ng tin tá»« URL (Web Scraping) - general-purpose

    Args:
        url: Link web cáº§n extract (cÃ³ thá»ƒ lÃ  sáº£n pháº©m, bÃ i viáº¿t, trang thÃ´ng tin)

    Returns:
        Dict chá»©a:
            - url: str
            - title: str - TiÃªu Ä‘á» trang
            - content: str - Ná»™i dung chÃ­nh
            - description: str - MÃ´ táº£
            - images: List[str] - Danh sÃ¡ch link áº£nh (náº¿u cÃ³)
            - metadata: Dict - ThÃ´ng tin bá»• sung

    Purpose:
        - Extract ná»™i dung tá»« báº¥t ká»³ trang web nÃ o
        - DÃ¹ng BeautifulSoup hoáº·c LlamaIndex web scraper
        - Há»— trá»£ cáº£ sáº£n pháº©m vÃ  bÃ i viáº¿t/content

    Reference: Section 6 - Data Extraction feature
    """
    try:
        # TODO: Implement web scraping
        # Use BeautifulSoup or LlamaIndex SimpleWebPageReader

        logger.info(f"âœ… Extracting web content from: {url}")

        # Placeholder
        return {
            "url": url,
            "title": "",
            "content": "",
            "description": "",
            "images": [],
            "metadata": {},
            "error": "Web content extraction chÆ°a Ä‘Æ°á»£c implement"
        }

    except Exception as e:
        logger.error(f"âŒ Error extracting web content: {e}")
        return {
            "url": url,
            "error": str(e)
        }


@mcp_server.tool()
async def search_youtube_videos(query: str, max_results: int = 5) -> Dict[str, Any]:
    """
    TÃ¬m video hÆ°á»›ng dáº«n trÃªn YouTube

    Args:
        query: Tá»« khÃ³a tÃ¬m kiáº¿m (vÃ­ dá»¥: "cÃ¡ch cho chÃ³ uá»‘ng thuá»‘c", "máº¹o chÄƒm sÃ³c mÃ¨o")
        max_results: Sá»‘ video tá»‘i Ä‘a (default: 5)

    Returns:
        Dict chá»©a:
            - query: str
            - videos: List[Dict] - Danh sÃ¡ch video
                - title: str
                - url: str - Link YouTube
                - thumbnail: str - Link thumbnail
                - channel: str - TÃªn kÃªnh
                - views: int - LÆ°á»£t xem

    Purpose:
        - Research Agent tÃ¬m video hÆ°á»›ng dáº«n, review, tutorials
        - Há»— trá»£ Medical Agent tÃ¬m video y táº¿
        - Tá»± Ä‘á»™ng nhÃºng link video vÃ o cÃ¢u tráº£ lá»i

    Reference: Section 6 - Video Integration feature
    """
    try:
        # Use YouTube Data API (náº¿u cÃ³ API key)
        # Hoáº·c dÃ¹ng DuckDuckGo search vá»›i site:youtube.com

        if settings.YOUTUBE_API_KEY:
            # TODO: Implement YouTube Data API v3
            pass
        else:
            # Fallback: DuckDuckGo search
            search_query = f"{query} site:youtube.com"
            web_result = await web_search(search_query, max_results)

            videos = [
                {
                    "title": result["title"],
                    "url": result["url"],
                    "thumbnail": "",
                    "channel": "",
                    "views": 0
                }
                for result in web_result["results"]
                if "youtube.com" in result["url"]
            ]

            logger.info(f"âœ… Found {len(videos)} YouTube videos")
            return {
                "query": query,
                "videos": videos
            }

    except Exception as e:
        logger.error(f"âŒ Error searching YouTube: {e}")
        return {
            "query": query,
            "videos": [],
            "error": str(e)
        }


# ===== TOOL METADATA =====
if __name__ == "__main__":
    print("ğŸ”§ Research Tools registered in FastMCP:")
    print("  - web_search")
    print("  - extract_web_content")
    print("  - search_youtube_videos")
    print("\nğŸ“Œ NOTE: Research Agent tÃ¬m báº¥t cá»© thá»© gÃ¬ trÃªn web Ä‘Æ°á»£c Main Agent giao phÃ³")

